Using TensorFlow backend.
running build_ext
(2,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
state_input (InputLayer)     (None, 1, 2)              0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 2)                 0         
_________________________________________________________________
dense_1 (Dense)              (None, 400)               1200      
_________________________________________________________________
activation_1 (Activation)    (None, 400)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 300)               120300    
_________________________________________________________________
activation_2 (Activation)    (None, 300)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 301       
_________________________________________________________________
activation_3 (Activation)    (None, 1)                 0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 1)                 0         
=================================================================
Total params: 121,801
Trainable params: 121,801
Non-trainable params: 0
_________________________________________________________________
None
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
observation_input (InputLayer)  (None, 1, 2)         0                                            
__________________________________________________________________________________________________
action_input (InputLayer)       (None, 1)            0                                            
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 2)            0           observation_input[0][0]          
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 3)            0           action_input[0][0]               
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 400)          1600        concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 400)          0           dense_4[0][0]                    
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 300)          120300      activation_4[0][0]               
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 300)          0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 1)            301         activation_5[0][0]               
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 1)            0           dense_6[0][0]                    
==================================================================================================
Total params: 122,201
Trainable params: 122,201
Non-trainable params: 0
__________________________________________________________________________________________________
None
2019-01-28 20:21:24.395469: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Training for 200000 steps ...
Interval 1 (0 steps performed)
10000/10000 [==============================] - 59s 6ms/step - reward: -286.2958
333 episodes - episode_reward: -8595.255 [-34654.760, -4660.862] - loss: 628695.454 - mean_squared_error: 1257390.907 - mean_q: -932.357

Interval 2 (10000 steps performed)
10000/10000 [==============================] - 62s 6ms/step - reward: -274.0405
333 episodes - episode_reward: -8228.831 [-320022.986, -1115.293] - loss: 732636.438 - mean_squared_error: 1465272.875 - mean_q: -1978.187

Interval 3 (20000 steps performed)
10000/10000 [==============================] - 66s 7ms/step - reward: -60.8988
334 episodes - episode_reward: -1826.137 [-9661.457, -1017.647] - loss: 2175036.500 - mean_squared_error: 4350073.000 - mean_q: -2179.109

Interval 4 (30000 steps performed)
10000/10000 [==============================] - 65s 7ms/step - reward: -70.4441
333 episodes - episode_reward: -2112.874 [-23963.955, -965.289] - loss: 1224575.875 - mean_squared_error: 2449151.750 - mean_q: -1770.147

Interval 5 (40000 steps performed)
10000/10000 [==============================] - 69s 7ms/step - reward: -36.5572
333 episodes - episode_reward: -1096.759 [-1445.937, -973.981] - loss: 979569.688 - mean_squared_error: 1959139.375 - mean_q: -1340.580

Interval 6 (50000 steps performed)
10000/10000 [==============================] - 70s 7ms/step - reward: -38.4138
334 episodes - episode_reward: -1153.725 [-1487.863, -1012.559] - loss: 992149.812 - mean_squared_error: 1984299.625 - mean_q: -940.650

Interval 7 (60000 steps performed)
10000/10000 [==============================] - 71s 7ms/step - reward: -36.0571
333 episodes - episode_reward: -1080.191 [-1443.105, -968.998] - loss: 1137337.500 - mean_squared_error: 2274675.000 - mean_q: -657.985

Interval 8 (70000 steps performed)
10000/10000 [==============================] - 74s 7ms/step - reward: -34.3897
333 episodes - episode_reward: -1032.260 [-1213.139, -978.975] - loss: 993710.000 - mean_squared_error: 1987420.000 - mean_q: -522.820

Interval 9 (80000 steps performed)
10000/10000 [==============================] - 80s 8ms/step - reward: -33.9325
334 episodes - episode_reward: -1019.000 [-1211.209, -972.345] - loss: 1564767.875 - mean_squared_error: 3129535.750 - mean_q: -448.676

Interval 10 (90000 steps performed)
10000/10000 [==============================] - 80s 8ms/step - reward: -33.4631
333 episodes - episode_reward: -1002.436 [-1092.248, -968.997] - loss: 457832.000 - mean_squared_error: 915664.000 - mean_q: -399.280

Interval 11 (100000 steps performed)
10000/10000 [==============================] - 83s 8ms/step - reward: -32.8904
333 episodes - episode_reward: -987.313 [-1064.194, -960.888] - loss: 379850.000 - mean_squared_error: 759700.000 - mean_q: -360.845

Interval 12 (110000 steps performed)
10000/10000 [==============================] - 85s 9ms/step - reward: -32.7104
334 episodes - episode_reward: -982.191 [-1112.188, -958.819] - loss: 266505.781 - mean_squared_error: 533011.562 - mean_q: -331.649

Interval 13 (120000 steps performed)
10000/10000 [==============================] - 88s 9ms/step - reward: -32.6272
333 episodes - episode_reward: -977.315 [-1069.065, -953.833] - loss: 271031.312 - mean_squared_error: 542062.625 - mean_q: -310.193

Interval 14 (130000 steps performed)
10000/10000 [==============================] - 91s 9ms/step - reward: -32.5292
333 episodes - episode_reward: -976.412 [-1084.145, -954.281] - loss: 681176.188 - mean_squared_error: 1362352.375 - mean_q: -300.005

Interval 15 (140000 steps performed)
10000/10000 [==============================] - 94s 9ms/step - reward: -32.5372
334 episodes - episode_reward: -977.081 [-1072.580, -956.199] - loss: 289682.219 - mean_squared_error: 579364.438 - mean_q: -288.808

Interval 16 (150000 steps performed)
10000/10000 [==============================] - 97s 10ms/step - reward: -32.5880
333 episodes - episode_reward: -976.302 [-1073.504, -956.009] - loss: 369633.156 - mean_squared_error: 739266.312 - mean_q: -278.529

Interval 17 (160000 steps performed)
10000/10000 [==============================] - 100s 10ms/step - reward: -32.3025
333 episodes - episode_reward: -969.567 [-1041.681, -954.153] - loss: 254335.438 - mean_squared_error: 508670.875 - mean_q: -270.702

Interval 18 (170000 steps performed)
10000/10000 [==============================] - 105s 10ms/step - reward: -32.2657
334 episodes - episode_reward: -968.826 [-1059.796, -953.141] - loss: 476595.906 - mean_squared_error: 953191.812 - mean_q: -262.644

Interval 19 (180000 steps performed)
10000/10000 [==============================] - 109s 11ms/step - reward: -32.2594
333 episodes - episode_reward: -966.377 [-1037.809, -951.435] - loss: 217150.125 - mean_squared_error: 434300.250 - mean_q: -254.863

Interval 20 (190000 steps performed)
10000/10000 [==============================] - 117s 12ms/step - reward: -32.2172
done, took 1665.862 seconds
Creating window glfw
-957.2387268061398 [[ 3.14159265  0.        ]
 [-2.82722024  3.14372417]
 [-2.57400971  2.53210523]
 [-2.36691988  2.07089837]
 [-2.16056803  2.06351844]
 [-1.93134052  2.2922751 ]
 [-1.75873634  1.72604179]
 [-1.59574815  1.62988195]
 [-1.44909343  1.46654722]
 [-1.30746352  1.41629903]
 [-1.17166413  1.35799394]
 [-1.05481064  1.1685349 ]
 [-0.9446129   1.1019774 ]
 [-0.83724457  1.07368326]
 [-0.73099326  1.06251313]
 [-0.63027133  1.00721934]
 [-0.53874558  0.91525741]
 [-0.4539398   0.84805785]
 [-0.37423562  0.79704178]
 [-0.30403837  0.70197249]
 [-0.24050877  0.63529608]
 [-0.18910981  0.51398952]
 [-0.15062053  0.38489283]
 [-0.12314088  0.27479652]
 [-0.10624034  0.16900534]
 [-0.096525    0.09715347]
 [-0.08960388  0.06921121]
 [-0.08385649  0.05747386]
 [-0.0785359   0.05320593]
 [-0.07341339  0.05122509]
 [-0.06842829  0.04985101]]

