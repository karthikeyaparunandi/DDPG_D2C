Using TensorFlow backend.
running build_ext
(2,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 2)                 0         
_________________________________________________________________
dense_1 (Dense)              (None, 32)                96        
_________________________________________________________________
activation_1 (Activation)    (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                1056      
_________________________________________________________________
activation_2 (Activation)    (None, 32)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 33        
_________________________________________________________________
activation_3 (Activation)    (None, 1)                 0         
=================================================================
Total params: 1,185
Trainable params: 1,185
Non-trainable params: 0
_________________________________________________________________
None
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
observation_input (InputLayer)  (None, 1, 2)         0                                            
__________________________________________________________________________________________________
action_input (InputLayer)       (None, 1)            0                                            
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 2)            0           observation_input[0][0]          
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 3)            0           action_input[0][0]               
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 32)           128         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32)           0           dense_4[0][0]                    
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 32)           1056        activation_4[0][0]               
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32)           0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 1)            33          activation_5[0][0]               
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 1)            0           dense_6[0][0]                    
==================================================================================================
Total params: 1,217
Trainable params: 1,217
Non-trainable params: 0
__________________________________________________________________________________________________
None
2019-01-27 22:51:02.984710: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Training for 200000 steps ...
Interval 1 (0 steps performed)
10000/10000 [==============================] - 52s 5ms/step - reward: -146.8319
333 episodes - episode_reward: -4407.362 [-752992.357, -1600.785] - loss: 38410853.859 - mean_squared_error: 76821707.718 - mean_q: -339.334

Interval 2 (10000 steps performed)
10000/10000 [==============================] - 54s 5ms/step - reward: -52.8698
333 episodes - episode_reward: -1586.882 [-13978.824, -857.665] - loss: 5050413.000 - mean_squared_error: 10100826.000 - mean_q: -729.466

Interval 3 (20000 steps performed)
10000/10000 [==============================] - 55s 6ms/step - reward: -33.5438
334 episodes - episode_reward: -1007.100 [-1628.793, -714.632] - loss: 3398316.750 - mean_squared_error: 6796633.500 - mean_q: -813.506

Interval 4 (30000 steps performed)
10000/10000 [==============================] - 57s 6ms/step - reward: -33.1525
333 episodes - episode_reward: -993.808 [-1390.775, -725.227] - loss: 2472130.000 - mean_squared_error: 4944260.000 - mean_q: -755.687

Interval 5 (40000 steps performed)
10000/10000 [==============================] - 59s 6ms/step - reward: -29.4785
333 episodes - episode_reward: -885.186 [-1542.579, -604.073] - loss: 1437455.000 - mean_squared_error: 2874910.000 - mean_q: -650.272

Interval 6 (50000 steps performed)
10000/10000 [==============================] - 62s 6ms/step - reward: -19.2046
334 episodes - episode_reward: -576.800 [-807.333, -517.487] - loss: 1511488.875 - mean_squared_error: 3022977.750 - mean_q: -353.529

Interval 7 (60000 steps performed)
10000/10000 [==============================] - 65s 6ms/step - reward: -17.9313
333 episodes - episode_reward: -536.979 [-814.634, -495.231] - loss: 152088.859 - mean_squared_error: 304177.719 - mean_q: -172.217

Interval 8 (70000 steps performed)
10000/10000 [==============================] - 67s 7ms/step - reward: -17.5517
333 episodes - episode_reward: -527.155 [-1177.013, -471.552] - loss: 1299779.125 - mean_squared_error: 2599558.250 - mean_q: -122.820

Interval 9 (80000 steps performed)
10000/10000 [==============================] - 70s 7ms/step - reward: -16.7511
334 episodes - episode_reward: -502.947 [-749.710, -465.511] - loss: 813232.812 - mean_squared_error: 1626465.625 - mean_q: -98.815

Interval 10 (90000 steps performed)
10000/10000 [==============================] - 73s 7ms/step - reward: -16.1288
333 episodes - episode_reward: -482.948 [-597.202, -465.678] - loss: 1024419.562 - mean_squared_error: 2048839.125 - mean_q: -100.181

Interval 11 (100000 steps performed)
10000/10000 [==============================] - 77s 8ms/step - reward: -18.4985
333 episodes - episode_reward: -555.129 [-802.215, -474.754] - loss: 580200.375 - mean_squared_error: 1160400.750 - mean_q: -89.459

Interval 12 (110000 steps performed)
10000/10000 [==============================] - 80s 8ms/step - reward: -17.3854
334 episodes - episode_reward: -522.299 [-830.795, -472.323] - loss: 720919.125 - mean_squared_error: 1441838.250 - mean_q: -90.623

Interval 13 (120000 steps performed)
10000/10000 [==============================] - 84s 8ms/step - reward: -16.6553
333 episodes - episode_reward: -498.785 [-594.163, -470.759] - loss: 593099.188 - mean_squared_error: 1186198.375 - mean_q: -91.753

Interval 14 (130000 steps performed)
10000/10000 [==============================] - 89s 9ms/step - reward: -16.1645
333 episodes - episode_reward: -485.392 [-695.769, -467.819] - loss: 327514.531 - mean_squared_error: 655029.062 - mean_q: -93.381

Interval 15 (140000 steps performed)
10000/10000 [==============================] - 89s 9ms/step - reward: -16.0569
334 episodes - episode_reward: -482.142 [-599.828, -466.534] - loss: 635646.500 - mean_squared_error: 1271293.000 - mean_q: -92.425

Interval 16 (150000 steps performed)
10000/10000 [==============================] - 92s 9ms/step - reward: -16.2252
333 episodes - episode_reward: -485.743 [-680.454, -467.636] - loss: 766413.188 - mean_squared_error: 1532826.375 - mean_q: -89.760

Interval 17 (160000 steps performed)
10000/10000 [==============================] - 95s 9ms/step - reward: -16.2064
333 episodes - episode_reward: -486.654 [-765.677, -471.204] - loss: 625341.500 - mean_squared_error: 1250683.000 - mean_q: -87.189

Interval 18 (170000 steps performed)
10000/10000 [==============================] - 99s 10ms/step - reward: -16.0500
334 episodes - episode_reward: -482.062 [-707.129, -469.065] - loss: 343065.844 - mean_squared_error: 686131.688 - mean_q: -81.444

Interval 19 (180000 steps performed)
10000/10000 [==============================] - 102s 10ms/step - reward: -16.0355
333 episodes - episode_reward: -480.162 [-653.718, -466.946] - loss: 1112746.375 - mean_squared_error: 2225492.750 - mean_q: -76.316

Interval 20 (190000 steps performed)
10000/10000 [==============================] - 106s 11ms/step - reward: -16.0646
done, took 1526.163 seconds
Creating window glfw
-474.509384726711 [[ 3.14159265e+00  0.00000000e+00]
 [-2.76917303e+00  2.38181399e+00]
 [-2.18084137e+00  2.96306325e+00]
 [-1.79824757e+00  1.50225700e+00]
 [-1.44349742e+00  1.84660779e+00]
 [-1.12100359e+00  1.55852351e+00]
 [-9.02832462e-01  9.76320439e-01]
 [-7.33053380e-01  8.42897413e-01]
 [-5.76724656e-01  7.98998385e-01]
 [-4.26165989e-01  7.77405244e-01]
 [-2.92302351e-01  6.73220297e-01]
 [-1.93780643e-01  4.65758369e-01]
 [-1.22486385e-01  3.44033386e-01]
 [-6.97830074e-02  2.54559201e-01]
 [-3.11050404e-02  1.86230342e-01]
 [-2.81193135e-03  1.36235722e-01]
 [ 1.79001607e-02  9.97627682e-02]
 [ 3.30655412e-02  7.30417663e-02]
 [ 4.41666550e-02  5.34608459e-02]
 [ 5.22896840e-02  3.91136413e-02]
 [ 5.82313564e-02  2.86065810e-02]
 [ 6.25760314e-02  2.09155164e-02]
 [ 6.57520619e-02  1.52882447e-02]
 [ 6.80733259e-02  1.11730461e-02]
 [ 6.97695525e-02  8.16401941e-03]
 [ 7.10089227e-02  5.96501840e-03]
 [ 7.19143844e-02  4.35775070e-03]
 [ 7.26364723e-02  3.59712522e-03]
 [ 7.32435824e-02  3.04472963e-03]
 [ 7.37558654e-02  2.56626629e-03]
 [ 7.41878219e-02  2.16418795e-03]]

reward = -10*(ob[0]**2 + ob[1]**2), no terminal reward.




